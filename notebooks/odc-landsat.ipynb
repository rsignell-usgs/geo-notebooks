{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5071afec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Landsat Collection 2 on AWS\n",
    "\n",
    "This notebook explores the Landsat Collection 2 data on AWS:\n",
    "\n",
    "- [Landsat Collection 2 STAC API](https://landsatlook.usgs.gov/stac-server), a catalog of Landsat data\n",
    "- [pystac-client](https://pystac-client.readthedocs.io/) for searching and access data\n",
    "- [OpenDataCube](https://www.opendatacube.org/) and [odc-stac](https://odc-stac.readthedocs.io/) for loading STAC assets and representing geospatial data as XArrays\n",
    "- [XArray](http://xarray.pydata.org/en/stable/), [pandas](https://pandas.pydata.org/) and [geopandas](https://geopandas.org/) for manipulating data\n",
    "- [Dask](https://dask.org/) for performing parallel, distributed computing\n",
    "- Various Dask cluster options, including LocalCluster, Dask Gateway, and [Coiled.io](https://coiled.io/), a service for hosting Dask clusters\n",
    "- [hvplot](https://hvplot.holoviz.org/) for visualization\n",
    "\n",
    "Shown will be how to find data for an area of interest, explore the resulting metadata, perform calculations, and visualize the results.\n",
    "\n",
    "Created by [Element 84](http://element84.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3120189b-b49c-41d5-a702-88548ba24b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial imports and reusable functions\n",
    "\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "from copy import deepcopy\n",
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "import pystac\n",
    "from shapely.geometry import shape\n",
    "import os\n",
    "import configparser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02e4ca3-f1cc-47f6-9f5a-2c7548827bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dict(GDAL_DISABLE_READDIR_ON_OPEN='EMPTY_DIR',\n",
    "           GDAL_MAX_RAW_BLOCK_CACHE_SIZE='200000000',\n",
    "           GDAL_SWATH_SIZE='200000000',\n",
    "           VSI_CURL_CACHE_SIZE='200000000')\n",
    "os.environ.update(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf3e6d-4176-4943-818f-bc88f6c483d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dict(AWS_REQUEST_PAYER='requester')\n",
    "os.environ.update(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e6132-9bc6-4a97-a00d-b2f40159251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for later reuse\n",
    "def plot_polygons(data, *args, **kwargs):\n",
    "    return data.hvplot.paths(*args, geo=True, tiles='OSM', xaxis=None, yaxis=None,\n",
    "                             frame_width=600, frame_height=600,\n",
    "                             line_width=3, **kwargs)\n",
    "\n",
    "# convert a list of STAC Items into a GeoDataFrame\n",
    "def items_to_geodataframe(items):\n",
    "    _items = []\n",
    "    for i in items:\n",
    "        _i = deepcopy(i)\n",
    "        _i['geometry'] = shape(_i['geometry'])\n",
    "        _items.append(_i)\n",
    "    gdf = gpd.GeoDataFrame(pd.json_normalize(_items))\n",
    "    for field in ['properties.datetime', 'properties.created', 'properties.updated']:\n",
    "        if field in gdf:\n",
    "            gdf[field] = pd.to_datetime(gdf[field])\n",
    "    gdf.set_index('properties.datetime', inplace=True)\n",
    "    return gdf\n",
    "\n",
    "# set pystac_client logger to DEBUG to see API calls\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger('pystac_client')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f100b1b",
   "metadata": {},
   "source": [
    "# Search for data\n",
    "\n",
    "Use pystac-client to find data in the Landsat STAC API. First, print up a table of all the STAC Collections in the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64615c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Landsat STAC API\n",
    "\n",
    "from pystac_client import Client\n",
    "URL = 'https://landsatlook.usgs.gov/stac-server'\n",
    "cat = Client.open(URL)\n",
    "print(cat)\n",
    "\n",
    "collections = [(c.id, c.title) for c in cat.get_collections()]\n",
    "pd.set_option(\"display.max_colwidth\", 150)\n",
    "df = pd.DataFrame(collections, columns=['id', 'title'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b0b19a",
   "metadata": {},
   "source": [
    "Fetch the collection of interest: Landsat Collection 2, Level 2 Surface Reflectance (landsat-c2l2-sr) and print the assets that are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21053106",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = 'landsat-c2l2-sr'\n",
    "\n",
    "collection = cat.get_collection(collection_id)\n",
    "pd.DataFrame.from_dict(collection.to_dict()['item_assets'], orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e0654",
   "metadata": {},
   "source": [
    "Change the AOI, search parameters here, and print how many matching scenes there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42062ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "\n",
    "aoi = gpd.read_file('../aois/HoM_WGS84_Box.geojson')\n",
    "geom = json.loads(aoi['geometry'].to_json())['features'][0]['geometry']\n",
    "\n",
    "# limit sets the # of items per page so we can see multiple pages getting fetched\n",
    "search = cat.search(\n",
    "    collections = [collection_id],\n",
    "    intersects = aoi['geometry'][0],\n",
    "    datetime = \"2021-10-01/2022-08-31\",\n",
    "    query = [\"eo:cloud_cover<25\"],\n",
    "    limit = 100\n",
    ")\n",
    "\n",
    "print(f\"{search.matched()} items found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734177ef",
   "metadata": {},
   "source": [
    "# Use GeoPandas to view footprints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946997a9",
   "metadata": {},
   "source": [
    "The cell below fetches all the STAC Items and updates the URLs to use the provided s3 URLs which can be used for direct access rather than the default https URLs. This is because the alternate extension is not yet supported in PySTAC, when it is there will be an easier way to specify which alternate URL, if any, to use for the assets.\n",
    "\n",
    "Then, we create a GeoDataFrame for visualizing the footprints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa5182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all items as a dictionary\n",
    "items_dict = search.get_all_items_as_dict()['features']\n",
    "\n",
    "# update URLs to use s3\n",
    "for item in items_dict:\n",
    "    for a in item['assets']:\n",
    "        if 'alternate' in item['assets'][a] and 's3' in item['assets'][a]['alternate']:\n",
    "            item['assets'][a]['href'] = item['assets'][a]['alternate']['s3']['href']\n",
    "        item['assets'][a]['href'] = item['assets'][a]['href'].replace('usgs-landsat-ard', 'usgs-landsat')\n",
    "\n",
    "# Create GeoDataFrame from Items\n",
    "items_gdf = items_to_geodataframe(items_dict)\n",
    "\n",
    "print(f\"{len(items_dict)} items found\")\n",
    "\n",
    "pd.reset_option(\"display.max_colwidth\")\n",
    "items_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d05f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_polygons(aoi) * items_gdf.hvplot.paths(geo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f258702",
   "metadata": {},
   "source": [
    "# OpenDataCube\n",
    "\n",
    "Now we'll turn the set of scenes into a virtual datacube. None of the data will actually be read yet.\n",
    "\n",
    "The configuration string (`cfg`) is for providing additional info not currently available in the STAC Items, but will be in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74858c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "cfg = \"\"\"---\n",
    "landat-c2l2-sr:\n",
    "  measurements:\n",
    "    '*':\n",
    "      dtype: uint16\n",
    "      nodata: 0\n",
    "      unit: 'm'\n",
    "\"\"\"\n",
    "cfg = yaml.load(cfg, Loader=yaml.CSafeLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08311f41",
   "metadata": {},
   "source": [
    "Here we load as a DataCube. A PySTAC ItemCollection is created from the found STAC Items, and we specify various parameters, such as bands of interest, chunk size, and geometry to clip the data to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583cd3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from odc.stac import stac_load\n",
    "\n",
    "# Create PySTAC ItemCollection\n",
    "item_collection = pystac.ItemCollection(items_dict)\n",
    "\n",
    "# default to CRS and resolution from first Item\n",
    "from pystac.extensions.projection import ProjectionExtension\n",
    "from pyproj import CRS\n",
    "\n",
    "dc = stac_load(item_collection,\n",
    "               bands=['red', 'blue', 'green', 'nir08'],\n",
    "               chunks={\"x\": 2048, \"y\": 2048},\n",
    "               groupby='solar_day',\n",
    "               stac_cfg=cfg,\n",
    "               geopolygon=geom,\n",
    ")\n",
    "dc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8920daa1",
   "metadata": {},
   "source": [
    "# Calculations\n",
    "\n",
    "We create an RGB datacube representation and generate an NDVI datacube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0adc4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = dc.odc.to_rgba(vmin=1, vmax=20000, bands=['red', 'green', 'blue'])\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = ((dc['nir08'] - dc['red']) / (dc['nir08'] + dc['red'])).clip(0, 1)\n",
    "ndvi.name = 'ndvi'\n",
    "ndvi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b11cdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Start Dask Client"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e337b85-d64a-4df9-bf1f-193482aad8f5",
   "metadata": {},
   "source": [
    "# Local Dask cluster\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "raw",
   "id": "23d1937b",
   "metadata": {},
   "source": [
    "# Remote Dask cluster using Coiled.io\n",
    "\n",
    "import coiled\n",
    "from dask.distributed import Client\n",
    "\n",
    "# start dask cluster on coiled.io\n",
    "cluster = coiled.Cluster(\n",
    "    n_workers=25, software=\"matthewhanson/geo-notebooks-basic\", backend_options={\"region\": \"us-west-2\"},\n",
    "    environ={\"GDAL_DISABLE_READDIR_ON_OPEN\": \"YES\", \"AWS_REQUEST_PAYER\": \"requester\"}\n",
    ")\n",
    "# re-use existing cluster\n",
    "#cluster = coiled.Cluster(name=\"matthewhanson-e6818fa6-e\")\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707f78c9-1390-4b01-b73f-7419b140857a",
   "metadata": {},
   "source": [
    "#### Dask Gateway Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a3e6f-f2d8-4bec-951e-36a637b74485",
   "metadata": {},
   "source": [
    "First we use a function to generate AWS environment variables from an AWS profile, then we pass these environment variables to the cluster so the workers can read from this requester pays bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093a8d4b-0a04-4602-a712-47ca300ac470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_credentials(profile='default', region='us-west-2', endpoint=None, cfile=None):\n",
    "    # Set AWS environment variables based on profile from the user credentials file\n",
    "    cp = configparser.ConfigParser()\n",
    "    if not cfile:\n",
    "        cfile=os.path.expanduser('~/.aws/credentials')\n",
    "    if not endpoint:\n",
    "        endpoint=f's3.{region}.amazonaws.com'\n",
    "    cp.read(cfile)\n",
    "    os.environ['aws_access_key_id'.upper()]=cp[profile]['aws_access_key_id']    \n",
    "    os.environ['aws_secret_access_key'.upper()]=cp[profile]['aws_secret_access_key']    \n",
    "    os.environ['aws_s3_endpoint'.upper()]=endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72321b1-4be4-4dfb-9425-82b26bd1265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a87cc-7208-4812-a951-90f23701a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import Gateway\n",
    "# instantiate dask gateway\n",
    "gateway = Gateway()\n",
    "\n",
    "# setup a cluster\n",
    "\n",
    "options = gateway.cluster_options()\n",
    "options.conda_environment='users/pangeo'\n",
    "options.profile = 'Medium Worker'\n",
    "\n",
    "# pass environment vars to workers\n",
    "# this includes AWS environment vars needed to access requester-pays and private buckets\n",
    "options.environment_vars = dict(os.environ)\n",
    "\n",
    "cluster = gateway.new_cluster(options)\n",
    "\n",
    "cluster.adapt(minimum=4, maximum=30)\n",
    "\n",
    "# get the client for the cluster\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3dd786-c7d8-46c9-9413-3111d9192d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22953d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compute\n",
    "\n",
    "Now, we kick off our Dask computation by using the Dask persist function, which will keep the data in memory on the cluster for faster access later.\n",
    "\n",
    "The Dask `compute` function is used when we actually want the data, such as displaying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ded5dee-cb60-4b5c-b8a8-7e856ae45b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = client.persist(vis)\n",
    "vis.plot.imshow(col='time', rgb='band', col_wrap=5, robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d06098-4a08-48f0-beb0-5c83f19f6aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "import panel as pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f400ecef-fd6f-4126-89b3-802a5bf57fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.spatial_ref.crs_wkt[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd80ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvplot_kwargs = dict(crs=32619, tiles='OSM', \n",
    "                frame_width=400, widgets={'time': pn.widgets.Select})\n",
    "\n",
    "vis.hvplot.rgb(x='x', y='y', bands='band', **hvplot_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad16c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ndvi = ndvi.compute()\n",
    "ndvi.hvplot(x='x', y='y', **hvplot_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aede574b-75a8-408f-bfc3-e12940774d1f",
   "metadata": {},
   "source": [
    "Create an animated GIF of NDVI over time using [geogif](https://geogif.readthedocs.io/en/latest/) with the fetched results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af2911-fe92-427d-b738-76159bce9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geogif import gif\n",
    "\n",
    "gif(ndvi, fps=1, cmap='YlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbe220b-fade-4090-b746-d8a710128f67",
   "metadata": {},
   "source": [
    "Explore how the mean NDVI changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c27e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ndvi_mean = ndvi.mean(dim=['x', 'y']).compute()\n",
    "ndvi_mean.hvplot(grid=True, title='Mean NDVI over time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb97978a",
   "metadata": {},
   "source": [
    "# Shutdown cluster\n",
    "\n",
    "Shut down the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gateway.stop_cluster(cluster_name=cluster.name)\n",
    "print(f'stopped {cluster.name}')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "users-pangeo",
   "language": "python",
   "name": "conda-env-users-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
